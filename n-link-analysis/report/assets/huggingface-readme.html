<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HuggingFace Dataset Documentation</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
        }

        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        header h1 {
            font-size: 2rem;
            margin-bottom: 0.5rem;
        }

        header p {
            font-size: 1rem;
            opacity: 0.9;
        }

        .nav-link {
            color: white;
            text-decoration: none;
            opacity: 0.9;
            font-size: 0.9rem;
        }

        .nav-link:hover {
            opacity: 1;
            text-decoration: underline;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem;
        }

        .content {
            background: white;
            border-radius: 8px;
            padding: 2rem;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        h1, h2, h3, h4, h5, h6 {
            color: #2c3e50;
            margin-top: 1.5rem;
            margin-bottom: 0.75rem;
        }

        h1 { font-size: 1.8rem; }
        h2 { font-size: 1.5rem; border-bottom: 2px solid #667eea; padding-bottom: 0.3rem; }
        h3 { font-size: 1.25rem; }
        h4 { font-size: 1.1rem; }

        p {
            margin-bottom: 1rem;
        }

        a {
            color: #667eea;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        ul, ol {
            margin-bottom: 1rem;
            padding-left: 2rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid #ddd;
            padding: 0.75rem;
            text-align: left;
        }

        th {
            background: #667eea;
            color: white;
            font-weight: 500;
        }

        tr:nth-child(even) {
            background: #f9f9f9;
        }

        tr:hover {
            background: #f0f0f0;
        }

        code {
            background: #f4f4f4;
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-family: "SF Mono", Consolas, monospace;
            font-size: 0.9em;
        }

        pre {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 1rem;
            border-radius: 6px;
            overflow-x: auto;
            margin: 1rem 0;
        }

        pre code {
            background: none;
            padding: 0;
            color: inherit;
        }

        img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
            margin: 1rem 0;
        }

        blockquote {
            border-left: 4px solid #667eea;
            margin: 1rem 0;
            padding-left: 1rem;
            color: #666;
            font-style: italic;
        }

        hr {
            border: none;
            border-top: 2px solid #eee;
            margin: 2rem 0;
        }

        .badge {
            display: inline-block;
            background: #e8f4f8;
            color: #2980b9;
            padding: 0.2rem 0.6rem;
            border-radius: 12px;
            font-size: 0.85rem;
            font-weight: 500;
        }

        footer {
            text-align: center;
            padding: 2rem;
            color: #666;
            font-size: 0.9rem;
        }

        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }

            .content {
                padding: 1rem;
            }

            header h1 {
                font-size: 1.5rem;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: 0.5rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <p><a href="gallery.html" class="nav-link">Back to Gallery</a></p>
        <h1>HuggingFace Dataset Documentation</h1>
        <p>N-Link Basin Analysis Project</p>
    </header>

    <div class="container">
        <div class="content">
<h1>Wikipedia N-Link Basin Analysis Dataset</h1>
<p><strong>Dataset for</strong>: Hugging Face</p>
<p><strong>Version</strong>: 1.0.0</p>
<p><strong>Created</strong>: 2026-01-01</p>
<p><strong>Source</strong>: English Wikipedia (enwiki-20251220)</p>
<p><strong>License</strong>: CC BY-SA 4.0 (same as Wikipedia)</p>
<hr>
<h2>Overview</h2>
<p>This dataset contains the complete <strong>N-Link Rule analysis</strong> of English Wikipedia's internal link graph. It demonstrates that Wikipedia's 17.9 million pages partition into deterministic "basins of attraction" under simple traversal rules, with a dramatic phase transition at N=5.</p>
<h3>What is the N-Link Rule?</h3>
<p>For any Wikipedia page, follow the <strong>Nth link</strong> in the article body repeatedly. Every page eventually reaches a <strong>cycle</strong> (closed loop). All pages flowing to the same cycle form its <strong>basin of attraction</strong>.</p>
<h3>Key Findings</h3>
<table>
<thead><tr>
<th>Finding</th>
<th>Value</th>
</tr></thead><tbody>
<tr>
<td>Total pages analyzed</td>
<td>17,972,018</td>
</tr>
<tr>
<td>Phase transition peak</td>
<td>N=5</td>
</tr>
<tr>
<td>Basin collapse factor</td>
<td>10-1000× (N=5 vs N=10)</td>
</tr>
<tr>
<td>Tunnel nodes</td>
<td>9,018 (switch basins across N)</td>
</tr>
<tr>
<td>Dominant tunneling mechanism</td>
<td>99.3% degree_shift</td>
</tr>
</tbody></table>
<hr>
<h2>Dataset Structure</h2>
<pre><code>
wikipedia-nlink-basins/
├── source/                      # Foundation data
│   ├── nlink_sequences.parquet  # Core: page_id → first 3873 links
│   └── pages.parquet            # Page metadata (id, title, namespace)
├── analysis/                    # Per-N basin assignments
│   └── branches_n=*_*.parquet   # Individual basin memberships
└── multiplex/                   # Cross-N analysis (main dataset)
    ├── multiplex_basin_assignments.parquet
    ├── tunnel_nodes.parquet
    ├── multiplex_edges.parquet
    └── *.tsv                    # Human-readable summaries
</code></pre>
<hr>
<h2>Core Files</h2>
<h3>1. Source Data</h3>
<h4><code>nlink_sequences.parquet</code> (687 MB, 17.97M rows)</h4>
<p>The foundation dataset: every Wikipedia page with its ordered link sequence.</p>
<table>
<thead><tr>
<th>Column</th>
<th>Type</th>
<th>Description</th>
</tr></thead><tbody>
<tr>
<td><code>page_id</code></td>
<td>int64</td>
<td>Wikipedia page ID</td>
</tr>
<tr>
<td><code>link_sequence</code></td>
<td>list[int64]</td>
<td>Ordered list of linked page_ids (first N links in article)</td>
</tr>
</tbody></table>
<p><strong>Usage</strong>: Compute basin membership for any N by following <code>link_sequence[N-1]</code> repeatedly.</p>
<pre><code>
import pandas as pd
df = pd.read_parquet(&#x27;nlink_sequences.parquet&#x27;)
# Get 5th link for page 12345
fifth_link = df[df.page_id == 12345][&#x27;link_sequence&#x27;].iloc[0][4]
</code></pre>
<h4><code>pages.parquet</code> (940 MB, 64.7M rows)</h4>
<p>Page metadata for resolving IDs to titles.</p>
<table>
<thead><tr>
<th>Column</th>
<th>Type</th>
<th>Description</th>
</tr></thead><tbody>
<tr>
<td><code>page_id</code></td>
<td>int32</td>
<td>Wikipedia page ID</td>
</tr>
<tr>
<td><code>namespace</code></td>
<td>int16</td>
<td>Wikipedia namespace (0 = main article)</td>
</tr>
<tr>
<td><code>title</code></td>
<td>string</td>
<td>Page title</td>
</tr>
<tr>
<td><code>is_redirect</code></td>
<td>bool</td>
<td>Whether page is a redirect</td>
</tr>
</tbody></table>
<hr>
<h3>2. Multiplex Analysis (Primary Dataset)</h3>
<h4><code>multiplex_basin_assignments.parquet</code> (11.7 MB, 2.13M rows)</h4>
<p>Unified table of basin assignments across all N values.</p>
<table>
<thead><tr>
<th>Column</th>
<th>Type</th>
<th>Description</th>
</tr></thead><tbody>
<tr>
<td><code>page_id</code></td>
<td>int64</td>
<td>Wikipedia page ID</td>
</tr>
<tr>
<td><code>N</code></td>
<td>int8</td>
<td>N-link rule value (3-10)</td>
</tr>
<tr>
<td><code>cycle_key</code></td>
<td>string</td>
<td>Basin/cycle identifier</td>
</tr>
<tr>
<td><code>canonical_cycle_id</code></td>
<td>string</td>
<td>Normalized cycle name</td>
</tr>
<tr>
<td><code>entry_id</code></td>
<td>int64</td>
<td>Entry point page_id</td>
</tr>
<tr>
<td><code>depth</code></td>
<td>int32</td>
<td>Steps from cycle under this N</td>
</tr>
</tbody></table>
<p><strong>Note</strong>: Only pages with analyzed cycles are included (~2M pages across N=3-10).</p>
<h4><code>tunnel_nodes.parquet</code> (9.7 MB, 2.02M rows)</h4>
<p>Per-page basin membership across N values, identifying tunnel nodes.</p>
<table>
<thead><tr>
<th>Column</th>
<th>Type</th>
<th>Description</th>
</tr></thead><tbody>
<tr>
<td><code>page_id</code></td>
<td>int64</td>
<td>Wikipedia page ID</td>
</tr>
<tr>
<td><code>basin_at_N3</code></td>
<td>string</td>
<td>Basin membership at N=3 (null if not analyzed)</td>
</tr>
<tr>
<td><code>basin_at_N4</code></td>
<td>string</td>
<td>Basin membership at N=4</td>
</tr>
<tr>
<td><code>basin_at_N5</code></td>
<td>string</td>
<td>Basin membership at N=5</td>
</tr>
<tr>
<td><code>basin_at_N6</code></td>
<td>string</td>
<td>Basin membership at N=6</td>
</tr>
<tr>
<td><code>basin_at_N7</code></td>
<td>string</td>
<td>Basin membership at N=7</td>
</tr>
<tr>
<td><code>n_distinct_basins</code></td>
<td>int8</td>
<td>Count of unique basins across N</td>
</tr>
<tr>
<td><code>is_tunnel_node</code></td>
<td>bool</td>
<td>True if page switches basins</td>
</tr>
</tbody></table>
<p><strong>Key Statistic</strong>: 9,018 pages are tunnel nodes (0.45%).</p>
<h4><code>multiplex_edges.parquet</code> (87 MB, 9.69M edges)</h4>
<p>The multiplex graph structure with both within-N and tunnel edges.</p>
<table>
<thead><tr>
<th>Column</th>
<th>Type</th>
<th>Description</th>
</tr></thead><tbody>
<tr>
<td><code>src_page_id</code></td>
<td>int64</td>
<td>Source page ID</td>
</tr>
<tr>
<td><code>src_N</code></td>
<td>int8</td>
<td>Source N value</td>
</tr>
<tr>
<td><code>dst_page_id</code></td>
<td>int64</td>
<td>Destination page ID</td>
</tr>
<tr>
<td><code>dst_N</code></td>
<td>int8</td>
<td>Destination N value</td>
</tr>
<tr>
<td><code>edge_type</code></td>
<td>string</td>
<td>"within_N" or "tunnel"</td>
</tr>
</tbody></table>
<hr>
<h3>3. Human-Readable Summaries (TSV)</h3>
<table>
<thead><tr>
<th>File</th>
<th>Rows</th>
<th>Description</th>
</tr></thead><tbody>
<tr>
<td><code>tunnel_frequency_ranking.tsv</code></td>
<td>9,018</td>
<td>Ranked tunnel nodes by importance score</td>
</tr>
<tr>
<td><code>tunnel_classification.tsv</code></td>
<td>9,018</td>
<td>Tunnel type per node</td>
</tr>
<tr>
<td><code>tunnel_mechanisms.tsv</code></td>
<td>9,134</td>
<td>Mechanism (degree_shift vs path_divergence) per transition</td>
</tr>
<tr>
<td><code>basin_flows.tsv</code></td>
<td>16</td>
<td>Cross-basin page flow counts</td>
</tr>
<tr>
<td><code>basin_stability_scores.tsv</code></td>
<td>9</td>
<td>Per-basin stability metrics</td>
</tr>
<tr>
<td><code>cycle_identity_map.tsv</code></td>
<td>15</td>
<td>Canonical cycle name mapping</td>
</tr>
</tbody></table>
<hr>
<h2>Key Cycles/Basins</h2>
<p>The analysis focuses on 9 major basins that capture ~2M pages at N=5:</p>
<table>
<thead><tr>
<th>Basin</th>
<th>N=5 Size</th>
<th>N=10 Size</th>
<th>Collapse</th>
</tr></thead><tbody>
<tr>
<td>Massachusetts ↔ Gulf_of_Maine</td>
<td>1,009,471</td>
<td>5,226</td>
<td>193×</td>
</tr>
<tr>
<td>Sea_salt ↔ Seawater</td>
<td>265,896</td>
<td>4,391</td>
<td>61×</td>
</tr>
<tr>
<td>Mountain ↔ Hill</td>
<td>188,968</td>
<td>801</td>
<td>236×</td>
</tr>
<tr>
<td>Autumn ↔ Summer</td>
<td>162,689</td>
<td>148</td>
<td>1,100×</td>
</tr>
<tr>
<td>Kingdom_(biology) ↔ Animal</td>
<td>112,805</td>
<td>7,867</td>
<td>14×</td>
</tr>
<tr>
<td>Latvia ↔ Lithuania</td>
<td>81,656</td>
<td>2,499</td>
<td>33×</td>
</tr>
</tbody></table>
<hr>
<h2>Empirical Findings</h2>
<h3>Phase Transition at N=5</h3>
<p>N=5 produces uniquely large basins. Basin sizes collapse by 10-1000× when moving to N=10.</p>
<h3>Tunneling Behavior</h3>
<ul>
<li><strong>9,018 pages</strong> switch basins as N changes</li>
<li><strong>99.3%</strong> of tunneling caused by "degree_shift" (different Nth link)</li>
<li><strong>N=5→N=6</strong> transition accounts for 53% of all tunneling</li>
<li>Shallow nodes (low depth) tunnel more than deep nodes (r = -0.83)</li>
</ul>
<h3>Hub Hypothesis Refuted</h3>
<p>Tunnel nodes have <strong>lower</strong> average out-degree (31.8) than non-tunnel nodes (34.0). Tunneling is about position (depth), not connectivity.</p>
<hr>
<h2>Theory Foundation</h2>
<p>This dataset validates predictions from <strong>N-Link Rule Theory</strong>:</p>
<ol>
<li><strong>Basin Partition Theorem</strong>: Every finite graph partitions into disjoint basins under any deterministic traversal rule.</li>
</ol>
<ol>
<li><strong>Multiplex Interpretation</strong>: Fixed-N basins are 1D slices of a higher-dimensional multiplex structure connected by "tunneling" at shared nodes.</li>
</ol>
<ol>
<li><strong>Phase Transition</strong>: There exists a critical N value where basin structure changes dramatically (empirically: N=5 for Wikipedia).</li>
</ol>
<hr>
<h2>Usage Examples</h2>
<h3>Find basin for any page at N=5</h3>
<pre><code>
import pandas as pd

# Load data
basins = pd.read_parquet(&#x27;multiplex/multiplex_basin_assignments.parquet&#x27;)

# Find basin for page_id 12345 at N=5
result = basins[(basins.page_id == 12345) &amp; (basins.N == 5)]
print(result[&#x27;canonical_cycle_id&#x27;].values)
</code></pre>
<h3>Identify tunnel nodes</h3>
<pre><code>
tunnels = pd.read_parquet(&#x27;multiplex/tunnel_nodes.parquet&#x27;)
tunnel_pages = tunnels[tunnels.is_tunnel_node]
print(f&quot;Tunnel nodes: {len(tunnel_pages):,}&quot;)
</code></pre>
<h3>Trace N-link path</h3>
<pre><code>
import pandas as pd

seqs = pd.read_parquet(&#x27;source/nlink_sequences.parquet&#x27;)
pages = pd.read_parquet(&#x27;source/pages.parquet&#x27;)

def trace_path(start_id, n, max_steps=50):
    &quot;&quot;&quot;Follow Nth link from start_id.&quot;&quot;&quot;
    path = [start_id]
    current = start_id
    for _ in range(max_steps):
        row = seqs[seqs.page_id == current]
        if row.empty:
            break
        links = row[&#x27;link_sequence&#x27;].iloc[0]
        if len(links) &lt; n:
            break  # HALT: not enough links
        current = links[n-1]
        if current in path:
            return path, current  # CYCLE found
        path.append(current)
    return path, None

path, cycle_entry = trace_path(12345, n=5)
</code></pre>
<hr>
<h2>Reproducibility</h2>
<h3>Source Data</h3>
<ul>
<li><strong>Wikipedia dump</strong>: enwiki-20251220 (December 2025)</li>
<li><strong>Extraction</strong>: Custom Python pipeline extracting first N links from article prose</li>
</ul>
<h3>Analysis Scripts</h3>
<p>All analysis scripts available at: <code>n-link-analysis/scripts/</code></p>
<p>Key scripts:</p>
<ul>
<li><code>trace-nlink-path.py</code> - Trace individual paths</li>
<li><code>map-basin-from-cycle.py</code> - Map complete basin from cycle</li>
<li><code>tunneling/run-tunneling-pipeline.py</code> - Complete tunneling analysis</li>
</ul>
<h3>Dependencies</h3>
<pre><code>
python &gt;= 3.10
pandas &gt;= 2.0
pyarrow &gt;= 14.0
duckdb &gt;= 0.9
plotly &gt;= 5.0 (for visualization)
dash &gt;= 2.0 (for interactive tools)
</code></pre>
<hr>
<h2>File Sizes Summary</h2>
<table>
<thead><tr>
<th>Category</th>
<th>Size</th>
<th>Files</th>
</tr></thead><tbody>
<tr>
<td>Source data</td>
<td>1.6 GB</td>
<td>2</td>
</tr>
<tr>
<td>Per-N analysis</td>
<td>50 MB</td>
<td>~50</td>
</tr>
<tr>
<td>Multiplex analysis</td>
<td>110 MB</td>
<td>20</td>
</tr>
<tr>
<td><strong>Total (minimal)</strong></td>
<td><strong>120 MB</strong></td>
<td><strong>5 core files</strong></td>
</tr>
<tr>
<td><strong>Total (complete)</strong></td>
<td><strong>1.8 GB</strong></td>
<td><strong>~75 files</strong></td>
</tr>
</tbody></table>
<h3>Minimal Dataset (Recommended for HF)</h3>
<p>For most use cases, only the multiplex directory is needed:</p>
<ul>
<li><code>multiplex_basin_assignments.parquet</code> (12 MB)</li>
<li><code>tunnel_nodes.parquet</code> (10 MB)</li>
<li><code>multiplex_edges.parquet</code> (87 MB)</li>
<li>TSV summaries (~5 MB)</li>
</ul>
<p><strong>Total: ~115 MB</strong></p>
<h3>Full Dataset</h3>
<p>Include <code>nlink_sequences.parquet</code> (687 MB) for complete reproducibility.</p>
<hr>
<h2>Citation</h2>
<p>If you use this dataset, please cite:</p>
<pre><code>
@dataset{wikipedia_nlink_basins_2026,
  title={Wikipedia N-Link Basin Analysis Dataset},
  author={[Your Name]},
  year={2026},
  publisher={Hugging Face},
  url={https://huggingface.co/datasets/[your-username]/wikipedia-nlink-basins}
}
</code></pre>
<hr>
<h2>Related Work</h2>
<ul>
<li><strong>N-Link Rule Theory</strong>: Formal proofs in <code>theories-proofs-conjectures/n-link-rule-theory.md</code></li>
<li><strong>Database Inference Graph Theory</strong>: Extension to typed graphs in <code>database-inference-graph-theory.md</code></li>
<li><strong>Tunneling Analysis Report</strong>: Detailed findings in <code>n-link-analysis/report/TUNNELING-FINDINGS.md</code></li>
</ul>
<hr>
<h2>Contact</h2>
<p>[Your contact information]</p>
<hr>
<p><strong>Last Updated</strong>: 2026-01-01</p>
        </div>
    </div>

    <footer>
        <p>Part of the Self-Reference Modeling Project</p>
        <p><a href="gallery.html">Return to Gallery</a></p>
    </footer>
</body>
</html>
